#:schema https://github.com/liblaf/llm-cli/raw/refs/heads/main/docs/schema/config.json
[completion]
model = "deepseek-v3"

[[router.model_list]]
model_name = "deepseek-v3"
litellm_params.model = "openai/deepseek-v3"
litellm_params.base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
litellm_params.api_key = '{{(rbwFields "Aliyun").api_key.value}}'

[[router.model_list]]
model_name = "qwen-max"
litellm_params.model = "openai/qwen-max"
litellm_params.base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
litellm_params.api_key = '{{(rbwFields "Aliyun").api_key.value}}'

[[router.model_list]]
model_name = "qwen-plus"
litellm_params.model = "openai/qwen-plus"
litellm_params.base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
litellm_params.api_key = '{{(rbwFields "Aliyun").api_key.value}}'

[[router.model_list]]
model_name = "qwen-turbo"
litellm_params.model = "openai/qwen-turbo"
litellm_params.base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
litellm_params.api_key = '{{(rbwFields "Aliyun").api_key.value}}'

[[router.model_list]]
model_name = "qwen-long"
litellm_params.model = "openai/qwen-long"
litellm_params.base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
litellm_params.api_key = '{{(rbwFields "Aliyun").api_key.value}}'

[[router.fallbacks]]
deepseek-v3 = ["qwen-max", "qwen-plus", "qwen-turbo", "qwen-long"]

[[router.fallbacks]]
qwen-max = ["qwen-plus", "qwen-turbo", "qwen-long"]
