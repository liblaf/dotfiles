# -*- mode: toml -*-
#:schema https://liblaf.github.io/lime/schemas/config.json

model = "gemini-2.5-pro"

# -------------------------------- DeepSeek --------------------------------
[[router.model_list]]
model_name = "deepseek-reasoner"
litellm_params.model = "deepseek/deepseek-reasoner"
litellm_params.api_key = '{{ (rbwFields "DeepSeek").LIBLAF_LIME_API_KEY.value }}'

[[router.model_list]]
model_name = "deepseek-chat"
litellm_params.model = "deepseek/deepseek-chat"
litellm_params.api_key = '{{ (rbwFields "DeepSeek").LIBLAF_LIME_API_KEY.value }}'

# -------------------------------- Dashscope -------------------------------
[[router.model_list]]
model_name = "qwen3-coder-plus"
litellm_params.model = "dashscope/qwen3-coder-plus"
litellm_params.api_key = '{{ (rbwFields "Aliyun").LIBLAF_LIME_API_KEY.value }}'

# --------------------------------- YutoAPI --------------------------------
[[router.model_list]]
model_name = "gemini-2.5-pro"
litellm_params.model = "openai/gemini-2.5-pro"
litellm_params.api_key = '{{ (rbwFields "YutoAPI").API_KEY.value }}'
litellm_params.base_url = "https://cn.gptapi.asia/v1"

[[router.context_window_fallbacks]]
deepseek-chat = ["qwen3-coder-plus"]

[[router.context_window_fallbacks]]
deepseek-reasoner = ["qwen3-coder-plus"]
